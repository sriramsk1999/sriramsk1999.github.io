---
title: 'What does it mean to do the most good?'
date: 2023-08-13
permalink: /posts/2023/08/effective-altruism/
tags:
  - altruism
  - givingwhatwecan
---

On Effective Altruism and what it means to do the most good. **Disclaimer** : This post is about the Effective Altruism philosophy (which I think is useful), not the movement (which has questionable supporters and goals [[1]](https://time.com/6252617/effective-altruism-sexual-harassment/) [[2]](https://www.theatlantic.com/ideas/archive/2022/11/cryptocurrency-effective-altruism-ftx-sam-bankman-fried/672149/) [[3]](https://www.vox.com/2015/8/10/9124145/effective-altruism-global-ai))


Altruism is a noble quality. Placing the welfare and happiness of other beings above your own and performing actions to their benefit *at a cost to yourself*, is considered a virtue in numerous cultures, religions and even fictional works.

There are numerous viewpoints as to **why** we consider altruism a virtue. Without getting into too much detail, they try to explain that, counterintuitively, helping others at a cost to yourself may end up helping you in the long run. Perhaps this is true for small scale altruism, such as giving your neighbours some salt when they run out. However, the odds of anonymously paying for the medical costs of a child halfway across the world and benefiting from it are infinitesimally small.

So let's set that aside that aspect of altruism for the sake of this post. Let us take for fact that altruism is a virtue and that we should strive to help others and do good in the short span of time we spend on this [Pale Blue Dot](https://www.planetary.org/worlds/pale-blue-dot). The question which then arises:

How do we do the most good?
======

Needless to say, there are many ways to do good. Feeding stray animals near your house, providing your computational resources to [Folding@Home](https://foldingathome.org/) to speed up drug discoveries, funding charities which provide underprivileged children education or any of a thousand thousand ways in which we can help make the world better. Now, some causes are more important than others. To illustrate with an absurd example, curing cancer is more important than feeding stray dogs. This isn't a controversial statement as these examples are massively different in the amount of impact they have.

However, when the causes are of similar magnitude, the waters get muddy. How do you pick between funding say, research into Parkinson's disease, or feeding a hundred children for a year? What about saving pandas or donating to an orphanage? And what about 'moonshot' causes, which can have tremendous impact, but are not likely to happen in the near future? There are no easy (or correct) answers to these questions. To guide us through these troubled waters, Effective Altruism comes to the rescue. Well, sort of.

Effective Altruism
======

The framework of Effective Altruism gives us the tools to help answer these questions. **Effective Altruism is the use of evidence and reason to maximize the good with a given amount of resources**. In effect, it attempts to bring a rigorous analysis to the causes that can be supported, and the 'amount' of good that supporting each of these causes will bring. 

The concept is intriguing. For better or for worse, most of us donate to causes close to our heart, to feel good about ourselves. Bringing an element of rationality into the picture and to consciously *maximize* the amount of good you do, even if the causes are not ones close to your heart, is admirable. On another level, I find that evaluating different problems against each other to be a great exercise in understanding your own values and what you consider important. 

In this post I attempt to enumerate the problems I consider most important to doing good. While I might come across as a cold, unfeeling sociopath I promise I'm not like that in real life. Despite my best efforts, this list will almost certainly be personal. My experiences have shaped me and my values, and these will undoubtedly reflect in the causes I deem most important. 

On Measuring "Good"
======

> When you can measure what you are speaking about, and express it in numbers, you know something about it, when you cannot express it in numbers, your knowledge is of a meager and unsatisfactory kind; it may be the beginning of knowledge, but you have scarely, in your thoughts advanced to the stage of science.
>
> -Lord Kelvin

To evaluate the impact of various problems, to compare them with each other, we must *measure* them. It would be absurd to say that the measurements in this post are the 'beginning of knowledge', as Lord Kelvin puts it, let alone science. Nevertheless, its a step in the right direction.

There are many factors involved in deciding what this *quantum of good* should be. I attempt to quantify the same through the following 3 dimensions:

**Human Life (HL)**{:.HumanLife} - Saving human lives is the archetypical altruistic act - (think firefighters running into burning buildings). Unanimously hailed as heroes and with good reason.

On a societal scale, this is measured with the *mortality rate*, a measure of the number of deaths per unit of time.
Any act which reduces the mortality rate is a 'good' act.

However, this is not quite sufficient. While the mortality rate of two countries might be the same, the *quality* of their health may not be the same.
Two people living to a hundred years does not imply both of them have had good health throughout.

Out of this need to measure both mortality (life/death) and *morbidity* (healthy/diseased) arises **Quality Adjusted Life Years (QALY)**.
[One QALY is one year in perfect health](https://en.wikipedia.org/wiki/Quality-adjusted_life_year). Various diseases are assigned <= 1 QALY depending on their seriousness.
For example, a year spent blind might be assigned 0.5 QALY. 
Crudely put, this would mean that two years without eyesight is "equivalent" to one year with, a controversial statement to say the least. 

However, these weights are typically estimated through surveys ("Would you rather stay blind and live 10 more years, or live for 5 years with perfect eyesight?") which does give them some utility.
Any cause which scores high on this metric should be a prominent choice.

Example causes - Medical care to those in poverty, subsidising simple surgeries with big impacts (e.g. cataract removal), vaccinations, providing food to malnourished children etc. 

**Human Quality of Life (HQoL)**{:.HumanQualityofLife}- **Human Life** captures the basic goals - causes which increase the life expectancy and health of humans.
Without a doubt, they should be the first priority for anyone wanting to make an impact.
However, in [Maslow's hierarchy of needs](https://en.wikipedia.org/wiki/Maslow%27s_hierarchy_of_needs), optimizing for QALYs would only tackle the needs at the bottom of the pyramid. 

Being sapient creatures with immense potential, humans require more than just life.
We need opportunities, education, social and economic mobility, disposable income, security and more.
Someone working a dead-end job might live a long and healthy life, but it's not *enough*. 
People deserve to have the opportunities that are easily available to those born more privileged.

The [European Union has a great article](https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Quality_of_life_indicators_-_measuring_quality_of_life) on why GDP is not a sufficient measure for the quality of life of citizens, and propose a 9 dimensional measure, covering everything mentioned above and more.

Worthy causes in this area should close the gap between underprivileged and privileged groups by providing them opportunities and awareness - scholarships and funding for rural schools, affordable internet access, pro bono legal services. 

**Moonshot Causes (MC)**{:.MoonshotCauses} - With the above two factors, we look at causes which preserve and enhance life and health, and provide opportunities to uplift those without.
Put another way, causes which strive to improve the state of humanity *now*.

But barring planet-scale disasters, humanity is here to stay.
This ties into another perspective of effective altruism, improving the lives of human beings in the future.
After all, over the next century, billions more human beings will be born, and the progress we make now could have an enormous impact on their lives.

These Moonshot Causes are gamechangers, capable of radically changing life as we know it.
These causes vary widely, from academic and industrial research to advocacy groups that help shape policy for the future. 
The most exciting causes like Artificial General Intelligence (AGI), and feasible nuclear fusion aren't really ones the common man can fund and are thus off the table. 
Besides, there are interested parties trying to solve these problems due to their mindboggling potential to make money. 

So, what then can we do with modest sums of money? Target the less "sexy" areas where there's no money to be made. 
The poster child of this, and probably the most important, is tackling climate change. 
Funding organizations trying to combat climate change and advocacy groups pushing for governments to make better regulations is a good option. 

Another cause that comes to mind is funding ethical AI research. Like any powerful tool, AI has massive potential for abuse, which we've seen already, from [discrimination](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-biasagainst-women-idUSKCN1MK08G) to [disinformation](https://cset.georgetown.edu/publication/ai-and-the-future-of-disinformation-campaigns/).

I believe these factors sufficiently cover the ways in which we ought to choose causes, and quantify each factor in the ${0-1}$ range, based on the magnitude of the impact generated by giving a small sum of money. With that overview, our framework is ready. Introducing **Sriram's Impact Measure (SIM)** $^{TM}$, a linear combination of the above factors, as a measure of goodness:

**SIM** $$\require{color} = w_1*\colorbox{red}{HL} + w_2*\colorbox{green}{HQoL} + w_3*\colorbox{blue}{MC}$$

Where $w_1=0.6, w_2=0.3, w_3=0.1$. The weights control which factors are given importance and are assigned what I believe are appropriate values. We ought to focus primarily on the lives being lost today, seek to improve those less privileged, and finally, keep the future in mind. In this framework, doing the most good boils down to evaluating causes and selecting those which maximize **SIMs**.

Before we get to actually evaluating the causes, a couple of caveats:
1. It bears reiterating that there is no *right* way to evaluate causes, just my attempt at a formal and (somewhat) explainable one.
2. I am assuming that donating money is the only way to be an effective altruist. This is not true. There are talented people working in key areas whose time and work is more important than any amount of money they could donate. For most of us, I posit that we can do much more good with our money than with our time, and so I'll be moving forward under the assumption that the only resource we can allocate is our money. To do more with your time, [80,000 Hours](https://80000hours.org/) provides guidance on how to choose high-impact careers which have a positive impact on the world.
 
Some Causes
======

Now, calculating the values to assign for a cause is hard. The number of factors to consider, and approximate values for each of them would take a serious amount of research and effort. 
In the interest of my sanity, I will be taking a handwavy approach. The factors have values in ${0-1}$ for each cause, where we assume $1$ to be the theoretical maximum possible impact a small donation could have, and $0$ to be flushing the money down the toilet. 
Based primarily on my biases, I will assign values along each dimension to the causes. It is left as an exercise to the reader to correct me.

* **Medical aid** - Probably the most straightforward path of effective altruism - save lives by donating to those who save lives. Millions of people in low-income coutries die from preventable diseases like malaria and tuberculosis. Malaria in particular, is infamous as one of humanity's biggest killers. However, it is also preventable/treatable, for small sums of money. [The Malaria Foundation asserts that just 100USD could protect 20 children from malaria](https://www.malariaconsortium.org/pages/donate-usa.htm), which is incredible. A "boring" choice, but perhaps the most important.\
 **HQ**{:.HumanLife} = 0.9, **HQoL**{:.HumanQualityofLife} = 0.0, **MC**{:.MoonshotCauses} = 0.0 \
Medical aid $$= 0.54$$ **SIM**.

* **Child Welfare** - Besides helping the next generation of humanity, this has the additional benefit of giving you warm and fuzzy feelings. Changing the trajectory of a child's life may yield outsized benefits in their (and our) future. For example, providing free midday meals to children at schools has the distinction of scoring well on all 3 dimensions of **SIM**. The meals themselves help combat malnourishment, the incentive of food encourages parents to send their children to school, and armed with the opportunities that education provides, there is a chance for people to rise above the circustances of their upbringing and make an impact on the world.\
 **HQ**{:.HumanLife} = 0.5, **HQoL**{:.HumanQualityofLife} = 0.7, **MC**{:.MoonshotCauses} = 0.4 \
Child Welfare $$= 0.55$$ **SIM**.

> I am, somehow, less interested in the weight and convolutions of Einstein’s brain than in the near certainty that people of equal talent have lived and died in cotton fields and sweatshops.
>
> -Stephen Jay Gould

* **Animal Welfare** - You may have noticed that the metrics I've listed all revolve entirely around humans, with nothing about feeding strays, reforming factory farming etc. I love animals as much as the next guy, but I believe the life of a human (or rather, a sapient being) is simply worth more. Would I save an endangered panda or a human? Obviously, a human. But would I save the last panda on earth or a human? A much harder question, to which I do not have a firm answer. (see below for thoughts on factory farming)\
**HQ**{:.HumanLife} = 0.0, **HQoL**{:.HumanQualityofLife} = 0.0, **MC**{:.MoonshotCauses} = 0.0 \
Animal Welfare $$= 0.0$$ **SIM**.

![A cute generated panda](/images/effective-altruism/baby_panda.jpg)
*Figure 1: I'm sorry, little one. [Source](https://stock.adobe.com/images/cute-and-humorous-baby-panda-hanging-from-bamboo-generative-ai/554521329)*
{: .center}

* **Climate Change** - Perhaps the largest threat humanity as a whole faces today is climate change. Political action seems woefully inadequate. To me, the best chances of fighting climate change appear to be technological advancements that change the landscape of what is possible. Energy generation accounts for nearly three-quarters of global greenhouse gas emissions. More efficient solar panels, ways to harvest renewable energy in a cheaper way, room temperature superconductors would go a long way to addressing the issue. A significant chunk of emissions also come from agricultural needs, the raising of crops and livestock. Affordable lab-grown meat has the dual benefit of benefiting both humans and animals, ending inhumane factory farming practices, while providing food at much lower emissions.\
**HQ**{:.HumanLife} = 0.0, **HQoL**{:.HumanQualityofLife} = 0.2, **MC**{:.MoonshotCauses} = 0.9 \
Climate change $$= 0.15$$ **SIM**

Some Charities
======

Picking the charities themselves, is more of legwork than discussion. You try to find a charity with a good track record, sufficiently large so that they can leverage economies of scale, and transparent finances. I'll be sticking to my own nation's charities - there are plenty of issues to solve in India, my rupees will go farther than if converted to another currency, and some awareness about existing charities makes my task a bit easier. Without further ado:

- [Akshaya Patra](https://www.akshayapatra.org/)
- [Pratham Education Foundation](https://www.pratham.org/)
- [Smile Foundation](https://www.smilefoundationindia.org/health/) 

Conclusion
======

As a freshly minted professional aiming to go back to school, at this point in time I cannot in good conscience pledge a significant portion of my income to the cause. Nonetheless I close this post by saying that I have taken the Trial Pledge (1% of income for 3 years) on [Giving What We Can](https://www.givingwhatwecan.org/), leaving this roadmap of causes I deem most valuable and a (somewhat obnoxious) declaration of my intent to donate.

There is so much discussion to be had on what causes to donate to, why, how much and so on. I would love to be called out on erroneous assumptions I've made and good causes I've overlooked. We're in the same boat of trying to do good, and with discussion, I believe we can come closer to the 'Path Of Most Good'.

<style>
  .HumanLife {background-color:red;}
  .HumanQualityofLife {background-color:green;}
  .MoonshotCauses {background-color:blue;}
  .center {text-align:center;}
</style>

*Feel free to [contact me](mailto:sriramsk1999@gmail.com) to share your thoughts!*

### Some resources for learning more about Effective Altruism

- [Effective Altruism](https://www.effectivealtruism.org/)
- [Giving What We Can](https://www.givingwhatwecan.org/)
- [80000 Hours](https://80000hours.org/)
